# OpenAI API key configuration
openai_api_key: "sk-proj-111"

# Ollama local models configuration
models:
  llama_3_1_8b_instruct_q8_0: "ollama/llama3.1:8b-instruct-q8_0"
  llama_3_1_8b_instruct_q5_K_S: "ollama/llama3.1:8b-instruct-q5_K_S"
  llama3_2_3b_instruct_q5_K_S: "ollama/llama3.2:3b-instruct-q5_K_S"
  llama3_2_1b_instruct_q5_K_S: "ollama/llama3.2:1b-instruct-q5_K_S"
  gemma2_27b_instruct_q2_K: "ollama/gemma2:27b-instruct-q2_K" # resource-intensive
  gemma2_9b_instruct_q5_K_S: "ollama/gemma2:9b-instruct-q5_K_S"
  gemma2_9b_instruct_q8_0: "ollama/gemma2:9b-instruct-q8_0"
  gemma2_2b_text_q5_K_S: "ollama/gemma2:2b-instruct-q5_K_S"
  gemma2_2b_instruct_q4_K_S: "ollama/gemma2:2b-instruct-q4_K_S"
  mistral12b_model: "ollama/mistral-nemo:12b-instruct-2407-q3_K_M" # resource-intensive
  mistral_nemo_12b_instruct_2407_q8_0: "ollama/mistral-nemo:12b-instruct-2407-q8_0" # resource-intensive
  mistral_nemo_12b_instruct_2407_q5_K_S: "ollama/mistral-nemo:12b-instruct-2407-q5_K_S"
embeddings:
  provider: "ollama"
  config:
    nomic_text_model: "nomic-embed-text:latest"
    mxbai_text_model: "ollama/mxbai-embed-large:latest"

server:
  url: "http://127.0.0.1:1234/v1/completions"

request:
  model:
    gemma-2-9b-it-GGUF: "gemma-2-9b-instruct"
    una-cybertron-7B-v2-GGUF: "una-cybertron-7b-v2"
    Llama-3.2-3B-Instruct-Q8_0-GGUF: "lama-3.2-3b-instruct-q8_0.gguf"
    Meta-Llama-3.1-8B-Instruct-GGUF: "meta-llama-3.1-8b-instruct"
    deepseek-math-7b-instruct-GGUF: "deepseek-math-7b-instruct"
